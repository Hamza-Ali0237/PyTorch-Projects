{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2549dfcb",
   "metadata": {},
   "source": [
    "# ResNet20 Trained On CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd70a553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (26.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cpu)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f085b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import CIFAR100\n",
    "import torchvision.transforms as transforms\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e99be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761]),\n",
    "        transforms.RandomErasing()\n",
    "    ])\n",
    "\n",
    "    test_val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "    ])\n",
    "\n",
    "    return train_transform, test_val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2084d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(batch_size=128):\n",
    "\n",
    "    train_transform, val_transform = get_transforms()\n",
    "\n",
    "    train_dataset = CIFAR100(root=\"./data\", train=True, transform=train_transform, download=True)\n",
    "    val_dataset = CIFAR100(root=\"./data\", train=False, transform=val_transform, download=True)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=2, \n",
    "        pin_memory=True, \n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=2, \n",
    "        pin_memory=True, \n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_setup(\n",
    "        model, lr=0.1, \n",
    "        momentum=0.9, \n",
    "        weight_decay=1e-4, \n",
    "        milestones=[100, 150], gamma=0.1\n",
    "    ):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr=lr, \n",
    "        momentum=momentum, \n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer=optimizer,\n",
    "        milestones=milestones,\n",
    "        gamma=gamma\n",
    "    )\n",
    "\n",
    "    return criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(device, num_classes=100):\n",
    "    \n",
    "    metrics = torchmetrics.MetricCollection([\n",
    "        torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=1),\n",
    "        torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=5)\n",
    "    ]).to(device)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, criterion, scheduler, metrics, device):\n",
    "    model.train()\n",
    "    loss_per_epoch = 0.0\n",
    "\n",
    "    metrics.reset()\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_per_epoch += loss.item()\n",
    "        metrics.update(output, labels)\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    \n",
    "    loss_per_epoch /= len(train_loader)\n",
    "    return metrics, loss_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, metrics, device):\n",
    "    model.eval()\n",
    "    loss_per_epoch = 0.0\n",
    "\n",
    "    metrics.reset()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            loss_per_epoch += loss.item()\n",
    "\n",
    "            metrics.update(output, labels)\n",
    "        \n",
    "    loss_per_epoch /= len(val_loader)\n",
    "    \n",
    "    return metrics, loss_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e39e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea3148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f096a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
