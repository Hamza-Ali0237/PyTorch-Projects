{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2549dfcb",
   "metadata": {},
   "source": [
    "# Custom ResNets Trained On CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd70a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR100\n",
    "import torchvision.transforms as transforms\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e99be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6981a4",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761]),\n",
    "        transforms.RandomErasing()\n",
    "    ])\n",
    "\n",
    "    test_val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "    ])\n",
    "\n",
    "    return train_transform, test_val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2084d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(batch_size=128):\n",
    "\n",
    "    train_transform, val_transform = get_transforms()\n",
    "\n",
    "    train_dataset = CIFAR100(root=\"./data\", train=True, transform=train_transform, download=True)\n",
    "    val_dataset = CIFAR100(root=\"./data\", train=False, transform=val_transform, download=True)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=2, \n",
    "        pin_memory=True, \n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=2, \n",
    "        pin_memory=True, \n",
    "        persistent_workers=True\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_setup(\n",
    "        model, lr=0.1, \n",
    "        momentum=0.9, \n",
    "        weight_decay=1e-4, \n",
    "        milestones=[100, 150], gamma=0.1\n",
    "    ):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr=lr, \n",
    "        momentum=momentum, \n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer=optimizer,\n",
    "        milestones=milestones,\n",
    "        gamma=gamma\n",
    "    )\n",
    "\n",
    "    return criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(device, num_classes=100):\n",
    "    \n",
    "    metrics = torchmetrics.MetricCollection({\n",
    "        'acc_top1': torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=1),\n",
    "        'acc_top5': torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=5)\n",
    "    }).to(device)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "        model, \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        scheduler, \n",
    "        metrics, \n",
    "        device\n",
    "    ):\n",
    "    \n",
    "    model.train()\n",
    "    loss_per_epoch = 0.0\n",
    "\n",
    "    metrics.reset()\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_per_epoch += loss.item()\n",
    "        metrics.update(output, labels)\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    \n",
    "    loss_per_epoch /= len(train_loader)\n",
    "    return metrics, loss_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, metrics, device):\n",
    "    model.eval()\n",
    "    loss_per_epoch = 0.0\n",
    "\n",
    "    metrics.reset()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            loss_per_epoch += loss.item()\n",
    "\n",
    "            metrics.update(output, labels)\n",
    "        \n",
    "    loss_per_epoch /= len(val_loader)\n",
    "    \n",
    "    return metrics, loss_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2929049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(train_hist, val_hist):\n",
    "    # Extract data\n",
    "    loss_train = train_hist['train_loss']\n",
    "    loss_val = val_hist['val_loss']\n",
    "    \n",
    "    acc1_train = train_hist['train_acc_top_1']\n",
    "    acc1_val = val_hist['val_acc_top_1']\n",
    "    \n",
    "    acc5_train = train_hist['train_acc_top_5']\n",
    "    acc5_val = val_hist['val_acc_top_5']\n",
    "\n",
    "    epochs = range(1, len(loss_train) + 1)\n",
    "    \n",
    "    # Create a 1x2 grid (Loss on left, Accuracy on right)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot Loss\n",
    "    ax1.plot(epochs, loss_train, 'b-', label='Training Loss', linewidth=2)\n",
    "    ax1.plot(epochs, loss_val, 'r-', label='Validation Loss', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_title('Loss Curves', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot Top-1 (Solid Lines)\n",
    "    ax2.plot(epochs, acc1_train, 'b-', label='Train Top-1', linewidth=2)\n",
    "    ax2.plot(epochs, acc1_val, 'r-', label='Val Top-1', linewidth=2)\n",
    "    \n",
    "    # Plot Top-5 (Dashed Lines)\n",
    "    ax2.plot(epochs, acc5_train, 'b--', label='Train Top-5', alpha=0.7)\n",
    "    ax2.plot(epochs, acc5_val, 'r--', label='Val Top-5', alpha=0.7)\n",
    "    \n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax2.set_title('Top-1 & Top-5 Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=10, loc='lower right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cifar100_learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06804508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_saliency_map(model, dataloader, device):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Select a batch from dataloader\n",
    "    images, labels = next(iter(dataloader))\n",
    "    \n",
    "    # Move the batch to GPU\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Select the first image and label from the batch\n",
    "    image, label = images[0], labels[0]\n",
    "\n",
    "    # Add batch dimension to the image\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    # Enable gradient tracking on the image\n",
    "    image.requires_grad_(True)\n",
    "\n",
    "    # Pass the image to the model (Forward Pass)\n",
    "    output = model(image)\n",
    "\n",
    "    # Find the predicted class\n",
    "    pred_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "    # Find raw scalar value of the predicted class\n",
    "    target_score = output[0, pred_class] # Shape: [1 -> Image, 100 -> Num Classes]\n",
    "\n",
    "    # Set model's gradient to zero\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Set image's pixels' gradients to zero\n",
    "    if image.grad is not None:\n",
    "        image.grad.zero_()\n",
    "    \n",
    "    # Perform Backward Pass on the target_score\n",
    "    target_score.backward()\n",
    "\n",
    "    # --- Extract Saliency Map ---\n",
    "    # Select image gradients and detach them\n",
    "    saliency = image.grad.detach()\n",
    "\n",
    "    # Remove batch dimension that was added earlier\n",
    "    saliency = saliency.squeeze()\n",
    "\n",
    "    # Take absolute value of every gradient\n",
    "    saliency = saliency.abs()\n",
    "\n",
    "    # ---  Normalize Saliency ---\n",
    "    # Subtract saliency by the minimum of the gradients\n",
    "    saliency -= saliency.min()\n",
    "\n",
    "    # Divide saliency by the maximum of the gradients\n",
    "    saliency /= saliency.max() + 1e-8\n",
    "\n",
    "    # Prepare original image for plotting\n",
    "    original_image = images[0].cpu().permute(1, 2, 0)\n",
    "\n",
    "    # Move saliency to CPU\n",
    "    saliency = saliency.cpu()\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Plot Original\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(original_image)\n",
    "    plt.title(f\"Original (Class: {labels[0].item()})\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Plot Saliency\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(saliency.cpu(), cmap='jet') # 'jet' or 'hot' are best for heatmaps\n",
    "    plt.title(f\"Saliency Map (Pred: {pred_class})\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5bf6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_cam(model, dataloader, device):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Select a batch from the dataloader\n",
    "    images, labels = next(iter(dataloader))\n",
    "\n",
    "    # Move the batch to the GPU\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Select first image and label from the batch\n",
    "    image, label = images[0], labels[0]\n",
    "\n",
    "    # Add batch dimension to the image\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    # Select last nn.Conv2d layer of the model\n",
    "    target_layer = model.res_block_3[2].block[3]\n",
    "\n",
    "    # Initialize empty feature_maps and gradients\n",
    "    feature_maps = None\n",
    "    gradients = None\n",
    "\n",
    "    # Define forward hook\n",
    "    def forward_hook(module, input, output):\n",
    "        nonlocal feature_maps\n",
    "        feature_maps = output\n",
    "\n",
    "    # Define backward hook\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        nonlocal gradients\n",
    "        gradients = grad_output[0]\n",
    "    \n",
    "    # Set the hooks on the target layer\n",
    "    forward_handle = target_layer.register_forward_hook(forward_hook)\n",
    "    backward_handle = target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "\n",
    "    # Find the predicted class\n",
    "    pred_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "    # Find the scalar value of the predicted class\n",
    "    target_score = output[0, pred_class]\n",
    "\n",
    "    # Set model gradients to zero\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Perform backward pass on target_score\n",
    "    target_score.backward()\n",
    "\n",
    "    # --- Generate CAM ---\n",
    "    # Find mean of gradients along height and width\n",
    "    weights = gradients.mean(dim=(2,3), keepdim=True)\n",
    "\n",
    "    # Find weighted sum of the feature maps\n",
    "    cam = (weights * feature_maps).sum(dim=1, keepdim=True)\n",
    "\n",
    "    # Apply ReLU\n",
    "    cam = F.relu(cam)\n",
    "\n",
    "    # Upsample the CAM\n",
    "    cam = F.interpolate(cam, size=(32, 32), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    # Remove the batch dimension that was added earlier\n",
    "    cam = cam.squeeze()\n",
    "\n",
    "    # --- Normalize CAM ---\n",
    "    cam -= cam.min()\n",
    "    cam /= cam.max() + 1e-8\n",
    "\n",
    "    # Detach from graph, move to CPU, convert to numpy\n",
    "    cam = cam.detach().cpu().numpy()\n",
    "\n",
    "    # Prepare origina image for plotting\n",
    "    original_image = images[0].cpu().permute(1, 2, 0)\n",
    "\n",
    "    # Plot the original image and GradCAM\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f\"Original Image (Label: {label.item()})\")\n",
    "    plt.imshow(original_image, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f\"Grad-CAM (Class: {pred_class})\")\n",
    "    plt.imshow(original_image, cmap=\"gray\")\n",
    "    plt.imshow(cam, cmap=\"jet\", alpha=0.5)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Remove the hooks, otherwise it will cause memory leaks in future training\n",
    "    forward_handle.remove()\n",
    "    backward_handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def __call__(self, val_loss, model):\n",
    "        \n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ee7d8",
   "metadata": {},
   "source": [
    "# Model #1: ResNet-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e39e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, downsample=None):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def _initial_forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        output = self._initial_forward(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        output += identity\n",
    "\n",
    "        output = F.relu(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea3148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet20(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(ResNet20, self).__init__()\n",
    "\n",
    "        self.initial_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        num_layers_per_block = 3\n",
    "\n",
    "        # Residual Blocks\n",
    "        self.res_block_1 = self._make_residual_block(16, 16, num_layers_per_block, stride=1)\n",
    "        self.res_block_2 = self._make_residual_block(16, 32, num_layers_per_block, stride=2)\n",
    "        self.res_block_3 = self._make_residual_block(32, 64, num_layers_per_block, stride=2)\n",
    "\n",
    "        # Global Average Pooling (GAP)\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        self.fc_layer = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_residual_block(self, in_channels, out_channels, num_layers, stride=1):\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(ResidualLayer(in_channels, out_channels, stride, downsample=downsample))\n",
    "\n",
    "        for _ in range(1, num_layers):\n",
    "            layers.append(ResidualLayer(out_channels, out_channels, stride=1, downsample=None))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out', non_linearity=\"relu\")\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, 0, 0.01)\n",
    "                init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.initial_conv(x)\n",
    "\n",
    "        x = self.res_block_1(x)\n",
    "        x = self.res_block_2(x)\n",
    "        x = self.res_block_3(x)\n",
    "\n",
    "        x = self.gap(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c6e66",
   "metadata": {},
   "source": [
    "## Training & Evaluation Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet20 = ResNet20().to(device)\n",
    "early_stopping = EarlyStopping(patience=10, min_delta=1e-3)\n",
    "\n",
    "train_loader, val_loader = get_loaders()\n",
    "criterion, optimizer, scheduler = train_setup(resnet20)\n",
    "train_metrics = get_metrics(device)\n",
    "val_metrics = get_metrics(device)\n",
    "\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f096a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = {\"train_loss\":[], \"train_acc_top_1\":[], \"train_acc_top_5\":[]}\n",
    "val_history = {\"val_loss\":[], \"val_acc_top_1\":[], \"val_acc_top_5\":[]}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    _, train_loss = train_one_epoch(resnet20, train_loader, optimizer, criterion, scheduler, train_metrics, device)\n",
    "    _, val_loss = validate(resnet20, val_loader, criterion, val_metrics, device)\n",
    "\n",
    "    train_results = train_metrics.compute()\n",
    "    val_results = val_metrics.compute()\n",
    "\n",
    "    train_acc_1 = train_results['acc_top1'].item()\n",
    "    train_acc_5 = train_results['acc_top5'].item()\n",
    "    \n",
    "    val_acc_1 = val_results['acc_top1'].item()\n",
    "    val_acc_5 = val_results['acc_top5'].item()\n",
    "\n",
    "    train_history['train_loss'].append(train_loss)\n",
    "    train_history['train_acc_top_1'].append(train_acc_1)\n",
    "    train_history['train_acc_top_5'].append(train_acc_5)\n",
    "\n",
    "    val_history['val_loss'].append(val_loss)\n",
    "    val_history['val_acc_top_1'].append(val_acc_1)\n",
    "    val_history['val_acc_top_5'].append(val_acc_5)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc_1:.2%} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc_1:.2%}\")\n",
    "    \n",
    "    early_stopping(val_loss, resnet20)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early Stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "resnet20.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\nTraining Complete!\")\n",
    "print(f\"Total Training Time: {end_time - start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(train_history, val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf9a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_saliency_map(resnet20, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a11985",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grad_cam(resnet20, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574098f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
