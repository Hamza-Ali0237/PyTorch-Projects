{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamza-Ali0237/PyTorch-Projects/blob/main/Intermediate/PyTorch-FineGrained-TransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Grained Transfer Learning"
      ],
      "metadata": {
        "id": "QC-o2kV-qRX2"
      },
      "id": "QC-o2kV-qRX2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90187b26",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "90187b26"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d1d8ea",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "17d1d8ea"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision as tv\n",
        "import torchmetrics as tm\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "xrBFl1M-WGnj"
      },
      "id": "xrBFl1M-WGnj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b805b81",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "4b805b81"
      },
      "outputs": [],
      "source": [
        "conf_dict = {\n",
        "    # Reproducibility\n",
        "    \"seed\": 42,\n",
        "\n",
        "    # Computing Device\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "\n",
        "    # Data Settings\n",
        "    \"root_dir\": \"./data\",\n",
        "    \"image_size\": 224,\n",
        "    \"batch_size\": 32,\n",
        "    \"num_workers\": 2,\n",
        "    \"pin_memory\": True,\n",
        "\n",
        "    # Model Settings\n",
        "    \"architecture\": \"resnet50\",   # Backbone Architecture\n",
        "    \"pretrained\": True,\n",
        "    \"num_classes\": 102,\n",
        "\n",
        "    # Training Hyperparameters\n",
        "    \"epochs\": 25,\n",
        "    \"lr_head\": 1e-3,              # LR for classifier head\n",
        "    \"lr_backbone\": 1e-4,          # Lower LR for fine-tuning backbone\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"label_smoothing\": 0.0,\n",
        "\n",
        "    # Scheduler\n",
        "    \"scheduler\": \"onecycle\",\n",
        "\n",
        "    # Imbalance Handling\n",
        "    \"use_class_weights\": True,\n",
        "    \"use_weighted_sampler\": False,\n",
        "\n",
        "    # Logging & Saving\n",
        "    \"log_every_n_steps\": 20,\n",
        "    \"save_best_by\": \"val_loss\",\n",
        "    \"checkpoint_dir\": \"No checkpoints for now\"\n",
        "}\n",
        "\n",
        "print(conf_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = conf_dict[\"device\"]"
      ],
      "metadata": {
        "id": "EQ1ag1Yjzx_J"
      },
      "id": "EQ1ag1Yjzx_J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22699315",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "22699315"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "SEED = conf_dict[\"seed\"]\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "## for speed over strict determinism, set deterministic=False and benchmark=True\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Transforms"
      ],
      "metadata": {
        "id": "BKW2pnQQZiBf"
      },
      "id": "BKW2pnQQZiBf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93affe98",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "93affe98"
      },
      "outputs": [],
      "source": [
        "# Normalization values (ImageNet)\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Traning Transforms (Augmentaion + Normalization)\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(\n",
        "        brightness = 0.2, contrast = 0.2, saturation = 0.2, hue = 0.1\n",
        "    ),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean = mean, std = std\n",
        "    )\n",
        "])\n",
        "\n",
        "# Validation & Test Transforms (No heavy augmentation, just resize and center)\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean = mean, std = std\n",
        "    )\n",
        "])\n",
        "\n",
        "test_transforms = val_transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "elcNredIQYw5"
      },
      "id": "elcNredIQYw5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Datasets\n",
        "train_dataset = Flowers102(root=conf_dict[\"root_dir\"], split=\"train\", transform=train_transforms, download=True)\n",
        "val_dataset = Flowers102(root=conf_dict[\"root_dir\"], split=\"val\", transform=val_transforms, download=True)\n",
        "test_dataset = Flowers102(root=conf_dict[\"root_dir\"], split=\"test\", transform=test_transforms, download=True)"
      ],
      "metadata": {
        "id": "Uiy3JtkxQYRu"
      },
      "id": "Uiy3JtkxQYRu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d733585c",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "d733585c"
      },
      "outputs": [],
      "source": [
        "# Define Default DataLoaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size = conf_dict[\"batch_size\"], shuffle = True,\n",
        "    num_workers = conf_dict[\"num_workers\"], pin_memory = conf_dict[\"pin_memory\"]\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size = conf_dict[\"batch_size\"], shuffle = False,\n",
        "    num_workers = conf_dict[\"num_workers\"], pin_memory = conf_dict[\"pin_memory\"]\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size = conf_dict[\"batch_size\"], shuffle = False,\n",
        "    num_workers = conf_dict[\"num_workers\"], pin_memory = conf_dict[\"pin_memory\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Class Imbalance\n",
        "\n",
        "# Count samples per class in training set\n",
        "targets = train_dataset.targets\n",
        "class_counts = Counter(targets)\n",
        "\n",
        "# Calculate weights: total_samples / (num_classes * count[class])\n",
        "classes = train_dataset.classes\n",
        "num_classes = len(classes)\n",
        "total_samples = len(train_dataset)\n",
        "class_weights = []\n",
        "\n",
        "for c in range(num_classes):\n",
        "  weight = total_samples / (num_classes * class_counts[c])\n",
        "  class_weights.append(weight)\n",
        "\n",
        "# Convert to tensor\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# Define loss with weights\n",
        "criterion = nn.CrossEntropyLoss(weight = class_weights)"
      ],
      "metadata": {
        "id": "SEqKIqQyyA7N"
      },
      "id": "SEqKIqQyyA7N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot distributions (counts vs weights)\n",
        "\n",
        "# Convert counts into a list aligned with class indices\n",
        "counts_list = [class_counts[c] for c in range(num_classes)]\n",
        "\n",
        "# Print first 10 classes as a quick sanity check\n",
        "for i in range(10):\n",
        "    print(f\"Class {i:3d} | Count: {counts_list[i]:4d} | Weight: {class_weights[i].item():.4f}\")\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(14,6))\n",
        "\n",
        "# Plot counts on left y-axis\n",
        "ax1.bar(range(num_classes), counts_list, alpha=0.6, label=\"Class Counts\")\n",
        "ax1.set_xlabel(\"Class Index\")\n",
        "ax1.set_ylabel(\"Number of Samples\")\n",
        "ax1.legend(loc=\"upper left\")\n",
        "\n",
        "# Plot weights on right y-axis\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(range(num_classes), class_weights.cpu().numpy(), 'r-', label=\"Class Weights\")\n",
        "ax2.set_ylabel(\"Class Weight\")\n",
        "ax2.legend(loc=\"upper right\")\n",
        "\n",
        "plt.title(\"Class Distribution vs. Computed Weights\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2-lb3JzSyA4l"
      },
      "id": "2-lb3JzSyA4l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "jRp3GzZg2YlL"
      },
      "id": "jRp3GzZg2YlL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained ResNet18\n",
        "model = tv.models.resnet18(\n",
        "    weights = models.ResNet18_Weights.DEFAULT\n",
        ")\n",
        "\n",
        "# Freeze all model parameters\n",
        "for params in model.parameters():\n",
        "  params.requires_grad = False\n",
        "\n",
        "# Get the number of input features to the final layer\n",
        "in_features = model.fc.in_features\n",
        "\n",
        "# Replace the final fc layer to match 102 classes\n",
        "model.fc = nn.Linear(in_features, 102)\n",
        "\n",
        "# Unfreeze only classifier parameters\n",
        "for params in model.fc.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Double-check which params will be trained\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(\"Trainable:\", name)"
      ],
      "metadata": {
        "id": "Og71Y1YeyA2S"
      },
      "id": "Og71Y1YeyA2S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "1pyAFNT4yAz5"
      },
      "id": "1pyAFNT4yAz5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "GmJBCXYT8Pwq"
      },
      "id": "GmJBCXYT8Pwq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Optmizer and Scheduler\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.fc.parameters(),\n",
        "    lr = conf_dict[\"head_lr\"],\n",
        "    weight_decay = conf_dict[\"weight_decay\"]\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer,\n",
        "    step_size = conf_dict[\"step_size\"],\n",
        "    gamma = conf_dict[\"gamma\"]\n",
        ")"
      ],
      "metadata": {
        "id": "i9Z7KfSO4WwY"
      },
      "id": "i9Z7KfSO4WwY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}