{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamza-Ali0237/PyTorch-Projects/blob/main/Intermediate/PyTorch-CelebA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f694dd",
      "metadata": {
        "id": "d4f694dd"
      },
      "source": [
        "# Multi-Label Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup & Configuration"
      ],
      "metadata": {
        "id": "ca7PScJTpwOR"
      },
      "id": "ca7PScJTpwOR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eccd8d9",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "3eccd8d9"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8be6df1d",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "8be6df1d"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision as tv\n",
        "import torchmetrics as tm\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CelebA\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "662e44af",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "662e44af"
      },
      "outputs": [],
      "source": [
        "# Configuration Dictionary\n",
        "cfg = {\n",
        "    # Reproducibility\n",
        "    \"seed\": 42,\n",
        "\n",
        "    # Computing Device\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "\n",
        "    # Data Settings\n",
        "    \"root_dir\": \"./data\",\n",
        "    \"image_size\": 224,\n",
        "    \"batch_size\": 32,\n",
        "    \"num_workers\": 2,\n",
        "    \"pin_memory\": True,\n",
        "    \"num_classes\": 40,\n",
        "\n",
        "    # Training Hyperparameters\n",
        "    \"epochs\": 25,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"label_smoothing\": 0.0,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "462fea46",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "462fea46"
      },
      "outputs": [],
      "source": [
        "device = cfg[\"device\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e340f11",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "6e340f11"
      },
      "outputs": [],
      "source": [
        "# Set Seed For Reproducibilty\n",
        "SEED = cfg[\"seed\"]\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.cuda.manua nl_seed_all(SEED)\n",
        "\n",
        "# Ensure Deterministic Behaviour\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform & Load Data"
      ],
      "metadata": {
        "id": "UVJSUeIGzr-h"
      },
      "id": "UVJSUeIGzr-h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6873d4a",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "b6873d4a"
      },
      "outputs": [],
      "source": [
        "# Normalization Values\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "image_size = cfg[\"image_size\"]\n",
        "\n",
        "# Training Transforms (Augmentation+ Normalization)\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(image_size),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(\n",
        "        brightness = 0.1, contrast = 0.1, saturation = 0.1, hue = 0.05\n",
        "    ),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean = mean, std = std\n",
        "    )\n",
        "])\n",
        "\n",
        "# Validation & Test Transforms\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean = mean, std = std\n",
        "    )\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29b82a5e",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "29b82a5e"
      },
      "outputs": [],
      "source": [
        "# Load Data\n",
        "root = cfg[\"root_dir\"]\n",
        "\n",
        "train_dataset = CelebA(\n",
        "    root = root, split = \"train\",\n",
        "    transform = train_transforms, download = True\n",
        ")\n",
        "\n",
        "val_dataset = CelebA(\n",
        "    root = root, split = \"val\",\n",
        "    transform = val_test_transforms, download = True\n",
        ")\n",
        "\n",
        "test_dataset = CelebA(\n",
        "    root = root, split = \"test\",\n",
        "    transform = val_test_transforms, download = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "527b8b7b",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "527b8b7b"
      },
      "outputs": [],
      "source": [
        "# Define DataLoaders\n",
        "batch_size = cfg[\"batch_size\"]\n",
        "num_workers = cfg[\"num_workers\"]\n",
        "pin_memory = cfg[\"pin_memory\"]\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size = batch_size,\n",
        "    shuffle = True, num_workers = num_workers,\n",
        "    pin_memory = pin_memory\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size = batch_size,\n",
        "    shuffle = False, num_workers = num_workers,\n",
        "    pin_memory = pin_memory\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size = batch_size,\n",
        "    shuffle = False, num_workers = num_workers,\n",
        "    pin_memory = pin_memory\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Class"
      ],
      "metadata": {
        "id": "h7ePDB9HhC8F"
      },
      "id": "h7ePDB9HhC8F"
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLabelCNN(nn.Module):\n",
        "  def __init__(self, num_classes, image_size):\n",
        "        super(MultiLabelClass, self).__init__()\n",
        "\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(3, 32, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "\n",
        "        nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "    # Dynamically Calculate Flattened Size\n",
        "    with torch.no_grad():\n",
        "      dummy = torch.zeros(1, 3, image_size, image_size)\n",
        "      feat_dim = self.features(dummy).view(1, -1).shape[1]\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        self.Flatten(),\n",
        "        self.Linear(feat_dim, 512),\n",
        "        self.ReLU(),\n",
        "        self.Dropout(0.5),\n",
        "        self.Linear(512, num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "M_Gpr2h7gq1l"
      },
      "id": "M_Gpr2h7gq1l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o6Sac7P7gqtf"
      },
      "id": "o6Sac7P7gqtf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A_jbknErgqqY"
      },
      "id": "A_jbknErgqqY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1lS_Sx04gqni"
      },
      "id": "1lS_Sx04gqni",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}