{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamza-Ali0237/PyTorch-Projects/blob/main/Intermediate/PyTorch-CelebA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f694dd",
      "metadata": {
        "id": "d4f694dd"
      },
      "source": [
        "# Multi-Label Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup & Configuration"
      ],
      "metadata": {
        "id": "ca7PScJTpwOR"
      },
      "id": "ca7PScJTpwOR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eccd8d9",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "3eccd8d9"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics datasets pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8be6df1d",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "8be6df1d"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision as tv\n",
        "import torchmetrics as tm\n",
        "from datasets import load_dataset\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "662e44af",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "662e44af"
      },
      "outputs": [],
      "source": [
        "# Configuration Dictionary\n",
        "cfg = {\n",
        "    # Reproducibility\n",
        "    \"seed\": 42,\n",
        "\n",
        "    # Computing Device\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "\n",
        "    # Data Settings\n",
        "    \"root_dir\": \"./data\",\n",
        "    \"image_size\": 224,\n",
        "    \"batch_size\": 32,\n",
        "    \"num_workers\": 2,\n",
        "    \"pin_memory\": True,\n",
        "    \"num_classes\": 40,\n",
        "\n",
        "    # Training Hyperparameters\n",
        "    \"epochs\": 25,\n",
        "    \"lr\": 1e-3,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"label_smoothing\": 0.0,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "epochs = cfg[\"epochs\"]\n",
        "lr = cfg[\"lr\"]\n",
        "weight_decay = cfg[\"weight_decay\"]\n",
        "num_classes = cfg[\"num_classes\"]\n",
        "image_size = cfg[\"image_size\"]"
      ],
      "metadata": {
        "id": "tU97BLD43qt5"
      },
      "id": "tU97BLD43qt5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "462fea46",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "462fea46"
      },
      "outputs": [],
      "source": [
        "# Setup Device\n",
        "device = cfg[\"device\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e340f11",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "6e340f11"
      },
      "outputs": [],
      "source": [
        "# Set Seed For Reproducibilty\n",
        "SEED = cfg[\"seed\"]\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(SEED)\n",
        "  torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Ensure Deterministic Behaviour\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform & Load Data"
      ],
      "metadata": {
        "id": "UVJSUeIGzr-h"
      },
      "id": "UVJSUeIGzr-h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6873d4a",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "b6873d4a"
      },
      "outputs": [],
      "source": [
        "# Normalization Values\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "image_size = cfg[\"image_size\"]\n",
        "\n",
        "# Training Transforms (Augmentation+ Normalization)\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(image_size),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(\n",
        "        brightness = 0.1, contrast = 0.1, saturation = 0.1, hue = 0.05\n",
        "    ),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean = mean, std = std\n",
        "    )\n",
        "])\n",
        "\n",
        "# Validation & Test Transforms\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean = mean, std = std\n",
        "    )\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29b82a5e",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "29b82a5e"
      },
      "outputs": [],
      "source": [
        "# Load Data (Using HuggingFace Instead Of PyTorch)\n",
        "celeba_data = load_dataset(\"flwrlabs/celeba\")\n",
        "print(celeba_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Custom Dataset Class\n",
        "class CelebADataset(Dataset):\n",
        "  def __init__(self, hf_split, transform = None):\n",
        "    self.dataset = hf_split\n",
        "    self.transform = transform\n",
        "    self.attr_names = [col for col in self.dataset.column_names if col not in [\"image\", \"celeb_id\"]]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # Image\n",
        "    image = self.dataset[idx][\"image\"]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "\n",
        "    # Multi-label Target Vector (40 Attributes)\n",
        "    label = torch.tensor([int(self.dataset[idx][attr] == 1) for attr in self.attr_names], dtype = torch.float32)\n",
        "\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "1tlJF-lf9FxY"
      },
      "id": "1tlJF-lf9FxY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Splits\n",
        "train_dataset = CelebADataset(celeba_data[\"train\"], transform = train_transforms)\n",
        "val_dataset = CelebADataset(celeba_data[\"valid\"], transform = val_test_transforms)\n",
        "test_dataset = CelebADataset(celeba_data[\"test\"], transform = val_test_transforms)"
      ],
      "metadata": {
        "id": "KgS_A-k1_Ivr"
      },
      "id": "KgS_A-k1_Ivr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "527b8b7b",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "527b8b7b"
      },
      "outputs": [],
      "source": [
        "# Define DataLoaders\n",
        "batch_size = cfg[\"batch_size\"]\n",
        "num_workers = cfg[\"num_workers\"]\n",
        "pin_memory = cfg[\"pin_memory\"]\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size = batch_size,\n",
        "    shuffle = True, num_workers = num_workers,\n",
        "    pin_memory = pin_memory\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size = batch_size,\n",
        "    shuffle = False, num_workers = num_workers,\n",
        "    pin_memory = pin_memory\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size = batch_size,\n",
        "    shuffle = False, num_workers = num_workers,\n",
        "    pin_memory = pin_memory\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training & Evaluation Functions"
      ],
      "metadata": {
        "id": "zXg8nx9Si-ys"
      },
      "id": "zXg8nx9Si-ys"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Evaluation Metrics\n",
        "\n",
        "# Accuracy\n",
        "accuracy = tm.classification.MultilabelAccuracy(\n",
        "    num_labels = num_classes,\n",
        "    threshold = 0.5\n",
        ").to(device)\n",
        "\n",
        "# F1 Score\n",
        "f1_macro = tm.classification.F1Score(\n",
        "    task = \"multilabel\",\n",
        "    num_labels = num_classes,\n",
        "    average = \"macro\",\n",
        "    threshold = 0.5\n",
        ").to(device)\n",
        "\n",
        "f1_micro = tm.classification.F1Score(\n",
        "    task = \"multilabel\",\n",
        "    num_labels = num_classes,\n",
        "    average = \"micro\",\n",
        "    threshold = 0.5\n",
        ").to(device)\n",
        "\n",
        "# Area Under ROC Curve (AUROC)\n",
        "auroc_macro = tm.classification.MultilabelAUROC(\n",
        "    num_labels = num_classes,\n",
        "    average = \"macro\"\n",
        ").to(device)\n",
        "\n",
        "# Mean Average Precision (mAP)\n",
        "map_macro = tm.classification.MultilabelAveragePrecision(\n",
        "    num_labels=num_classes,\n",
        "    average=\"macro\"\n",
        ").to(device)\n",
        "\n",
        "map_micro = tm.classification.MultilabelAveragePrecision(\n",
        "    num_labels=num_classes,\n",
        "    average=\"micro\"\n",
        ").to(device)\n",
        "\n",
        "metrics_dict = {\n",
        "    \"accuracy\": accuracy,\n",
        "    \"f1_macro\": f1_macro,\n",
        "    \"f1_micro\": f1_micro,\n",
        "    \"auroc_macro\": auroc_macro,\n",
        "    \"map_macro\": map_macro,\n",
        "    \"map_micro\": map_micro\n",
        "}"
      ],
      "metadata": {
        "id": "o6Sac7P7gqtf"
      },
      "id": "o6Sac7P7gqtf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training & Validation Function\n",
        "def train_eval_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, metrics_dict):\n",
        "\n",
        "  # Store History\n",
        "  history = {\n",
        "      \"train_loss\": [], \"val_loss\": [],\n",
        "      \"train_acc\": [], \"val_acc\": [],\n",
        "      \"val_f1_macro\": [], \"val_f1_micro\": [],\n",
        "      \"val_auroc_macro\": [], \"val_map_macro\": [], \"val_map_micro\": []\n",
        "  }\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    # Training Phase\n",
        "    model.train()\n",
        "    epoch_train_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "      epoch_train_loss += loss.item()\n",
        "\n",
        "      preds = torch.sigmoid(outputs)\n",
        "      metrics_dict[\"accuracy\"](preds, labels)\n",
        "\n",
        "    epoch_train_loss /= len(train_loader)\n",
        "    epoch_train_acc = metrics_dict[\"accuracy\"].compute().item()\n",
        "    metrics_dict[\"accuracy\"].reset()\n",
        "\n",
        "    history[\"train_loss\"].append(epoch_train_loss)\n",
        "    history[\"train_acc\"].append(epoch_train_acc)\n",
        "\n",
        "    # Validation Phase\n",
        "    model.eval()\n",
        "    epoch_val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        epoch_val_loss += loss.item()\n",
        "\n",
        "        preds = torch.sigmoid(outputs)\n",
        "\n",
        "        # Update All Validation Metrics\n",
        "        metrics_dict[\"accuracy\"](preds, labels)\n",
        "        metrics_dict[\"f1_macro\"](preds, labels)\n",
        "        metrics_dict[\"f1_micro\"](preds, labels)\n",
        "        metrics_dict[\"auroc_macro\"](preds, labels)\n",
        "        metrics_dict[\"map_macro\"](preds, labels)\n",
        "        metrics_dict[\"map_micro\"](preds, labels)\n",
        "\n",
        "    epoch_val_loss /= len(val_loader)\n",
        "    epoch_val_acc = metrics_dict[\"accuracy\"].compute().item()\n",
        "    epoch_val_f1_macro = metrics_dict[\"f1_macro\"].compute().item()\n",
        "    epoch_val_f1_micro = metrics_dict[\"f1_micro\"].compute().item()\n",
        "    epoch_val_auroc_macro = metrics_dict[\"auroc_macro\"].compute().item()\n",
        "    epoch_val_map_macro = metrics_dict[\"map_macro\"].compute().item()\n",
        "    epoch_val_map_micro = metrics_dict[\"map_micro\"].compute().item()\n",
        "\n",
        "    # Reset Metrics\n",
        "    for metric in metrics_dict.value():\n",
        "      metric.reset()\n",
        "\n",
        "    # Save History\n",
        "    history[\"val_loss\"].append(epoch_val_loss)\n",
        "    history[\"val_acc\"].append(epoch_val_acc)\n",
        "    history[\"val_f1_macro\"].append(epoch_val_f1_macro)\n",
        "    history[\"val_f1_micro\"].append(epoch_val_f1_micro)\n",
        "    history[\"val_auroc_macro\"].append(epoch_val_auroc_macro)\n",
        "    history[\"val_map_macro\"].append(epoch_val_map_macro)\n",
        "    history[\"val_map_micro\"].append(epoch_val_map_micro)\n",
        "\n",
        "    # Print Progress\n",
        "    print(\n",
        "        f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "        f\"Train Loss: {epoch_train_loss:.4f}, Acc: {epoch_train_acc:.4f} | \"\n",
        "        f\"Val Loss: {epoch_val_loss:.4f}, Acc: {epoch_val_acc:.4f}, \"\n",
        "        f\"F1_macro: {epoch_val_f1_macro:.4f}, F1_micro: {epoch_val_f1_micro:.4f}, \"\n",
        "        f\"AUROC_macro: {epoch_val_auroc_macro:.4f}, \"\n",
        "        f\"mAP_macro: {epoch_val_map_macro:.4f}, mAP_micro: {epoch_val_map_micro:.4f}\"\n",
        "    )\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "A_jbknErgqqY"
      },
      "id": "A_jbknErgqqY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Training History Function\n",
        "def plot_train_history(history):\n",
        "\n",
        "    # Loss\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
        "    plt.plot(history[\"val_loss\"], label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training vs Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Accuracy\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(history[\"train_acc\"], label=\"Train Accuracy\")\n",
        "    plt.plot(history[\"val_acc\"], label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Training vs Validation Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # F1 Scores\n",
        "    if \"val_f1_macro\" in history:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(history[\"val_f1_macro\"], label=\"Val F1 Macro\")\n",
        "        plt.plot(history[\"val_f1_micro\"], label=\"Val F1 Micro\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"F1 Score\")\n",
        "        plt.title(\"Validation F1 Scores\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    # AUROC\n",
        "    if \"val_auroc_macro\" in history:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(history[\"val_auroc_macro\"], label=\"Val AUROC Macro\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"AUROC\")\n",
        "        plt.title(\"Validation AUROC\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    # mAP\n",
        "    if \"val_map_macro\" in history:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(history[\"val_map_macro\"], label=\"Val mAP Macro\")\n",
        "        plt.plot(history[\"val_map_micro\"], label=\"Val mAP Micro\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"mAP\")\n",
        "        plt.title(\"Validation mAP\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "NeJFaBzBtUmn"
      },
      "id": "NeJFaBzBtUmn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Testing Function\n",
        "def test_model(model, test_loader, criterion, device, metrics_dict):\n",
        "  model.eval()\n",
        "  test_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "      preds = torch.sigmoid(outputs)\n",
        "\n",
        "      # Update Metrics\n",
        "      metrics_dict[\"accuracy\"](preds, labels)\n",
        "      metrics_dict[\"f1_macro\"](preds, labels)\n",
        "      metrics_dict[\"f1_micro\"](preds, labels)\n",
        "      metrics_dict[\"auroc_macro\"](preds, labels)\n",
        "      metrics_dict[\"map_macro\"](preds, labels)\n",
        "      metrics_dict[\"map_micro\"](preds, labels)\n",
        "\n",
        "  test_loss /= len(test_loader)\n",
        "\n",
        "  # Compute Metrics\n",
        "  test_results = {\n",
        "      \"loss\": test_loss,\n",
        "      \"accuracy\": metrics_dict[\"accuracy\"].compute().item(),\n",
        "      \"f1_macro\": metrics_dict[\"f1_macro\"].compute().item(),\n",
        "      \"f1_micro\": metrics_dict[\"f1_micro\"].compute().item(),\n",
        "      \"auroc_macro\": metrics_dict[\"auroc_macro\"].compute().item(),\n",
        "      \"map_macro\": metrics_dict[\"map_macro\"].compute().item(),\n",
        "      \"map_micro\": metrics_dict[\"map_micro\"].compute().item(),\n",
        "  }\n",
        "\n",
        "  # Reset Metics\n",
        "  for metric in metrics_dict.values():\n",
        "    metric.reset()\n",
        "\n",
        "  # Print Results\n",
        "  print(\n",
        "      f\"Test Results:\\n\"\n",
        "      f\"Loss: {test_results['loss']:.4f}\\n\"\n",
        "      f\"Accuracy: {test_results['accuracy']:.4f}\\n\"\n",
        "      f\"F1 Macro: {test_results['f1_macro']:.4f}, \"\n",
        "      f\"F1 Micro: {test_results['f1_micro']:.4f}\\n\"\n",
        "      f\"AUROC Macro: {test_results['auroc_macro']:.4f}\\n\"\n",
        "      f\"mAP Macro: {test_results['map_macro']:.4f}, \"\n",
        "      f\"mAP Micro: {test_results['map_micro']:.4f}\"\n",
        "  )\n",
        "\n",
        "  return test_results"
      ],
      "metadata": {
        "id": "1lS_Sx04gqni"
      },
      "id": "1lS_Sx04gqni",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Optimizer, Criterion, Scheduler\n",
        "def train_utils(model, lr, weight_decay, train_loader, num_epochs):\n",
        "\n",
        "  # Define Optimizer\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr = lr, weight_decay = weight_decay)\n",
        "\n",
        "  # Define Criterion\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  # Define OneCycleLR Scheduler\n",
        "  steps_per_epoch = math.ceil(len(train_loader))\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "      optimizer,\n",
        "      max_lr = lr,\n",
        "      steps_per_epoch = steps_per_epoch,\n",
        "      epochs = num_epochs\n",
        "  )\n",
        "\n",
        "  return optimizer, criterion, scheduler"
      ],
      "metadata": {
        "id": "USn88b0gzhMB"
      },
      "id": "USn88b0gzhMB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Class"
      ],
      "metadata": {
        "id": "h7ePDB9HhC8F"
      },
      "id": "h7ePDB9HhC8F"
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLabelCNN(nn.Module):\n",
        "  def __init__(self, num_classes, image_size):\n",
        "    super(MultiLabelCNN, self).__init__()\n",
        "\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(3, 32, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "\n",
        "        nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "\n",
        "    # Dynamically Calculate Flattened Size\n",
        "    with torch.no_grad():\n",
        "      dummy = torch.zeros(1, 3, image_size, image_size)\n",
        "      feat_dim = self.features(dummy).view(1, -1).shape[1]\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(feat_dim, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "M_Gpr2h7gq1l"
      },
      "id": "M_Gpr2h7gq1l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate Model Class\n",
        "model = MultiLabelCNN(num_classes, image_size)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "7aPCi6SBycWL"
      },
      "id": "7aPCi6SBycWL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train MultiLabelCNN Model"
      ],
      "metadata": {
        "id": "nxXuA0iJ1YsU"
      },
      "id": "nxXuA0iJ1YsU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate Training Utils\n",
        "optimizer, criterion, scheduler = train_utils(\n",
        "    model, lr, weight_decay, train_loader, epochs\n",
        ")"
      ],
      "metadata": {
        "id": "waKbhSli1cF_"
      },
      "id": "waKbhSli1cF_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train & Evaluate (On Validation Split) Model\n",
        "history = train_eval_model(\n",
        "    model, train_loader, val_loader,\n",
        "    criterion, optimizer, scheduler,\n",
        "    epochs, device, metrics_dict\n",
        ")"
      ],
      "metadata": {
        "id": "5WI4cDkS3_g6"
      },
      "id": "5WI4cDkS3_g6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Training History\n",
        "plot_train_history(history)"
      ],
      "metadata": {
        "id": "jHyFbEah4nuE"
      },
      "id": "jHyFbEah4nuE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate MultiLabelCNN Model"
      ],
      "metadata": {
        "id": "jte_fvBMYX6A"
      },
      "id": "jte_fvBMYX6A"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model On Test Data\n",
        "test_results = test_model(model, test_loader, criterion, device, metrics_dict)"
      ],
      "metadata": {
        "id": "6b9PSrESDLtD"
      },
      "id": "6b9PSrESDLtD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_results)"
      ],
      "metadata": {
        "id": "TWUj1iphY379"
      },
      "id": "TWUj1iphY379",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}