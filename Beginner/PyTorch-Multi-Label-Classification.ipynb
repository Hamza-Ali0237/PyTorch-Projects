{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c504013c",
   "metadata": {},
   "source": [
    "# Multi-Label Image Classification on MLRS Net Dataset\n",
    "Dataset Link: [https://www.kaggle.com/datasets/vigneshwar472/mlrs-net]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a4bfd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07dc4326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (26.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.10.0+cu128)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.15.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.24.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=2.0.0->torchmetrics) (1.3.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.3-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.15.3 torchmetrics-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b6d328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f9cdf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6db8065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = \"/content/drive/MyDrive/mlrs_dataset/train\"\n",
    "val_dir = \"/content/drive/MyDrive/mlrs_dataset/validation\"\n",
    "test_dir = \"/content/drive/MyDrive/mlrs_dataset/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5978bf3",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47fedcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLRSDataset(Dataset):\n",
    "    def __init__(self, images_dir, csv_path, image_transforms=None, classes=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.image_transorms = image_transforms\n",
    "        \n",
    "        # Load and parse the CSV\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.df[\"labels\"] = self.df[\"labels\"].apply(ast.literal_eval)\n",
    "        \n",
    "        if classes is None:\n",
    "            self.classes = sorted(list(set([label for sublist in self.df[\"labels\"] for label in sublist])))\n",
    "        else:\n",
    "            self.classes = classes\n",
    "\n",
    "        self.mlb = MultiLabelBinarizer(classes=self.classes)\n",
    "        self.mlb.fit(self.df[\"labels\"])\n",
    "\n",
    "        self.image_paths = [os.path.join(self.images_dir, f\"{name}.jpg\") for name in self.df[\"image_id\"]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.image_transorms:\n",
    "            image = self.image_transorms(image)\n",
    "\n",
    "        current_labels = self.df[\"labels\"].iloc[index]\n",
    "        binary_vector = self.mlb.transform([current_labels]).squeeze()\n",
    "        binary_tensor = torch.from_numpy(binary_vector).float()\n",
    "\n",
    "        return image, binary_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f984a2",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11ef8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_dir, val_dir, test_dir, batch_size=128):\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "    \n",
    "    val_test_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    train_labels = os.path.join(train_dir, os.listdir(train_dir)[0])\n",
    "    train_images = os.path.join(train_dir, os.listdir(train_dir)[1])\n",
    "    train_dataset = MLRSDataset(train_images, train_labels, train_transforms)\n",
    "    \n",
    "    val_labels = os.path.join(val_dir, os.listdir(val_dir)[0])\n",
    "    val_images = os.path.join(val_dir, os.listdir(val_dir)[1])\n",
    "    val_dataset = MLRSDataset(val_images, val_labels, val_test_transforms)\n",
    "    \n",
    "    test_labels = os.path.join(test_dir, os.listdir(test_dir)[0])\n",
    "    test_images = os.path.join(test_dir, os.listdir(test_dir)[1])\n",
    "    test_dataset = MLRSDataset(test_images, test_labels, val_test_transforms)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a02f8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(device, num_classes=60):\n",
    "    metrics = torchmetrics.MetricCollection({\n",
    "        \"accuracy\": torchmetrics.classification.MultilabelAccuracy(num_labels=num_classes, average=\"macro\"),\n",
    "        \"precision\": torchmetrics.classification.MultilabelPrecision(num_labels=num_classes, average=\"macro\"),\n",
    "        \"recall\": torchmetrics.classification.MultilabelRecall(num_labels=num_classes, average=\"macro\"),\n",
    "    }).to(device)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91d3c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_setup(model):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.1, patience=3\n",
    "    )\n",
    "\n",
    "    return criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e19c3d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, metrics, device):\n",
    "    model.train()\n",
    "    metrics.reset()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        metrics.update(outputs, labels)\n",
    "    \n",
    "    epoch_loss /= len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3c6bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, metrics, device):\n",
    "    model.eval()\n",
    "    metrics.reset()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            epoch_loss + loss.item()\n",
    "\n",
    "            metrics.update(outputs, labels)\n",
    "    \n",
    "    epoch_loss /= len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8acf266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(train_losses, val_losses, train_accs, val_accs):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accs, 'b-', label='Training Acc')\n",
    "    plt.plot(epochs, val_accs, 'r-', label='Validation Acc')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2913445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_plot_single_image(model, image_path, true_labels, transforms, classes, device):\n",
    "    model.eval()\n",
    "    raw_image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = transforms(raw_image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)\n",
    "        probs = torch.sigmoid(logits).squeeze()\n",
    "        \n",
    "    predicted_indices = (probs > 0.5).nonzero(as_tuple=True)[0].cpu().numpy()\n",
    "    predicted_strings = [classes[i] for i in predicted_indices]\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(raw_image)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    title = f\"Actual: {true_labels}\\nPredicted: {predicted_strings}\"\n",
    "    color = 'green' if set(true_labels) == set(predicted_strings) else 'red'\n",
    "    \n",
    "    plt.title(title, color=color, fontsize=12, pad=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe694154",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408aa4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineCNN(nn.Module):\n",
    "    def __init__(self, num_classes=60):\n",
    "        super(BaselineCNN, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7f6c5c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc2f87b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = BaselineCNN().to(device)\n",
    "\n",
    "train_loader, val_loader, test_loader = get_loaders(train_dir, val_dir, test_dir)\n",
    "train_metrics, val_metrics, test_metrics = get_metrics(device), get_metrics(device), get_metrics(device)\n",
    "criterion, optimizer, scheduler = training_setup(baseline_model)\n",
    "\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5f2287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = {\"train_loss\":[], \"train_acc\":[]}\n",
    "val_history = {\"val_loss\":[], \"val_acc\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e676fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Epoch 1 Started...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1} Started...\\n\")\n",
    "\n",
    "    train_loss = train(baseline_model, train_loader, criterion, optimizer, train_metrics, device)\n",
    "    val_loss = validate(baseline_model, val_loader, criterion, val_metrics, device)\n",
    "\n",
    "    train_results = train_metrics.compute()\n",
    "    val_results = val_metrics.compute()\n",
    "\n",
    "    train_history[\"train_loss\"].append(train_loss)\n",
    "    train_history[\"train_acc\"].append(train_results[\"accuracy\"].item())\n",
    "    \n",
    "    val_history[\"val_loss\"].append(val_loss)\n",
    "    val_history[\"val_acc\"].append(val_results[\"accuracy\"].item())\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}/{EPOCHS} | Current LR: {current_lr} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad62f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(train_history[\"train_loss\"], val_history[\"val_loss\"], train_history[\"train_acc\"], val_history[\"val_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, value in train_results.items():\n",
    "    print(f\"Train {metric.capitalize()}: {value.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, value in val_results.items():\n",
    "    print(f\"Val {metric.capitalize()}: {value.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66cc5c9",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd67cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = validate(baseline_model, test_loader, criterion, test_metrics)\n",
    "test_results = test_metrics.compute()\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"Test {metric.capitalize()}: {value.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16220f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b0d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
