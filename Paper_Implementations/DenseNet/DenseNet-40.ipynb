{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3fbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629036d",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b9096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size=128):\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.490, 0.451), (0.214, 0.197, 0.191))\n",
    "\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.490, 0.451), (0.214, 0.197, 0.191))\n",
    "\n",
    "    ])\n",
    "    \n",
    "    train_dataset = CIFAR10(\n",
    "        root=\"./data\", train=True, download=True, transform=train_transform,\n",
    "    )\n",
    "\n",
    "    test_dataset = CIFAR10(\n",
    "        root=\"./data\", train=False, download=True, transform=test_transform,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc1225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_protocol(model, lr=0.1, momentum=0.9, weight_decay=0.0001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer=optimizer,\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=5,\n",
    "        threshold=0.0001\n",
    "    )\n",
    "\n",
    "    return criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e5f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    loss_per_epoch = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_per_epoch += loss.item()\n",
    "\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    loss_per_epoch /= len(train_loader)\n",
    "    accuracy = correct / total\n",
    "    return loss_per_epoch, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    loss_per_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss_per_epoch += loss.item()\n",
    "\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    loss_per_epoch /= len(test_loader)\n",
    "\n",
    "    return loss_per_epoch, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7fb647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(train_losses, val_losses, train_accs, val_accs):\n",
    "\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Plot loss curves\n",
    "    ax1.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    ax1.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot accuracy curves\n",
    "    ax2.plot(epochs, train_accs, 'b-', label='Training Accuracy')\n",
    "    ax2.plot(epochs, val_accs, 'r-', label='Validation Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc50ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(train_losses, val_losses, train_accs, val_accs):\n",
    "\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Plot loss curves\n",
    "    ax1.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    ax1.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot accuracy curves\n",
    "    ax2.plot(epochs, train_accs, 'b-', label='Training Accuracy')\n",
    "    ax2.plot(epochs, val_accs, 'r-', label='Validation Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94fb96",
   "metadata": {},
   "source": [
    "# DenseNet-40 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5127a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DenseLayer, self).__init__()\n",
    "\n",
    "        self.dense_layer = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.dense_layer(x)\n",
    "        return torch.cat([x, out], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40416fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_layers):\n",
    "        super(DenseBlock, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        in_channels = in_channels\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(DenseLayer(in_channels, growth_rate))\n",
    "            in_channels += growth_rate\n",
    "\n",
    "        self.dense_block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dense_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.transition(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec5ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet40(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k=12, L=40, num_classes=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            k (int): Growth rate,\n",
    "            L (int): Number of dense layers \n",
    "        \"\"\"\n",
    "        \n",
    "        super(DenseNet40, self).__init__()\n",
    "\n",
    "        # Initial number of features\n",
    "        self.num_init_features = 16\n",
    "        \n",
    "        # Initial Convolutional Block\n",
    "        self.initial_conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                3, self.num_init_features, kernel_size=3, stride=1, padding=1, bias=False\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Dense Blocks and Transition Layers\n",
    "        self.dense_blocks = self._make_dense_block(k, (L - 4) // 3, 3)\n",
    "\n",
    "        # Final BatchNorm and ReLU\n",
    "        self.final_bn = nn.BatchNorm2d(self.num_features)\n",
    "        self.final_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Global Average Pooling layer\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        self.classifier = nn.Linear(self.num_features, num_classes)\n",
    "    \n",
    "    def _make_dense_block(self, growth_rate, num_layers, num_blocks):\n",
    "        dense_blocks = []\n",
    "\n",
    "        num_features = self.num_init_features\n",
    "\n",
    "        for _ in range(num_blocks):\n",
    "            dense_blocks.append(DenseBlock(num_features, growth_rate, num_layers))\n",
    "            \n",
    "            num_features = num_features + num_layers * growth_rate # num_features + num_layers * growth_rate\n",
    "            \n",
    "            if _ != num_blocks - 1:  # No transition layer after the last dense block\n",
    "                dense_blocks.append(TransitionLayer(num_features, num_features))\n",
    "        \n",
    "        self.num_features = num_features\n",
    "\n",
    "        return nn.Sequential(*dense_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        x = self.dense_blocks(x)\n",
    "        x = self.final_bn(x)\n",
    "        x = self.final_relu(x)\n",
    "        x = self.gap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
