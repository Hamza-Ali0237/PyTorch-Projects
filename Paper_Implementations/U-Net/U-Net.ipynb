{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf47610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa2af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder / Contracting Path\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    def forward(self, x):\n",
    "        feat = self.conv(x) # The skip connection\n",
    "        out = self.pool(feat) # The input for the next layer\n",
    "        return feat, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a86666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bottleneck\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812cb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder / Expanding Path\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(out_channels * 2, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=2),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=2),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, skip):\n",
    "        x = self.upconv(x)\n",
    "        # # Concatenate along the channel dimension (dim=1)\n",
    "        x = torch.cat([skip, x], dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b092a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(enc_feat, target_tensor):\n",
    "    _, _, h, w = target_tensor.shape\n",
    "    enc_h, enc_w = enc_feat.shape[2], enc_feat.shape[3]\n",
    "\n",
    "    delta_h = enc_h - h\n",
    "    delta_w = enc_w - w\n",
    "\n",
    "    return enc_feat[:, :, delta_h // 2 : enc_h - delta_h // 2, delta_w // 2 : enc_w - delta_w // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.encoder = self._make_encoder_block(in_channels=1, out_channels=64, num_blocks=5)\n",
    "        self.decoder = self._make_decoder_block(in_channels, out_channels, num_blocks=4)\n",
    "    \n",
    "    def _make_encoder_block(self, in_channels, out_channels, num_blocks):\n",
    "        encoder_blocks = []\n",
    "\n",
    "        for _ in range(num_blocks):\n",
    "            encoder_blocks.append(Encoder(in_channels, out_channels))\n",
    "\n",
    "            in_channels = out_channels\n",
    "            out_channels = out_channels * 2\n",
    "        \n",
    "        return nn.Sequential(*encoder_blocks)\n",
    "    \n",
    "    def _make_decoder_block(self, in_channels, out_channels, num_blocks):\n",
    "        encoder_blocks = []\n",
    "\n",
    "        for _ in range(num_blocks):\n",
    "            encoder_blocks.append(Decoder(in_channels, out_channels))\n",
    "\n",
    "            in_channels = out_channels\n",
    "            out_channels = out_channels * 2\n",
    "        \n",
    "        return nn.Sequential(*encoder_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.encoder(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6289994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8b674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74176f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f2397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
