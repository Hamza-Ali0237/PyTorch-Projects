{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063baa5a",
   "metadata": {},
   "source": [
    "# ResNet-18 Model From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bea68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d271c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e875a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size=256):\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4471), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4471), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "    ])\n",
    "    \n",
    "    train_dataset = CIFAR10(\n",
    "        root=\"./data\", train=True, download=True, transform=train_transform,\n",
    "    )\n",
    "\n",
    "    test_dataset = CIFAR10(\n",
    "        root=\"./data\", train=False, download=True, transform=test_transform,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_protocol(model, lr=0.1, momentum=0.9, weight_decay=0.0001):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer=optimizer,\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=5,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    return loss, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f823ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
